{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13524b2a",
   "metadata": {},
   "source": [
    "# Comparing All Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c91d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shapely.geometry import MultiPoint\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%run data_cleaning.ipynb\n",
    "%run optimization_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9845194",
   "metadata": {},
   "source": [
    "### Import all necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c2d3d0-d5f5-4652-888a-0bad9cb9d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_locations = pd.read_csv(r\"data\\CensusTractCentroids.csv\")\n",
    "pop_centers = pd.read_csv(r\"data\\PopCenters.csv\")\n",
    "metro_locations = pd.read_csv(r\"data\\MetroLinkStations_REGISTERED.csv\")\n",
    "north_south_locations = pd.read_csv(r\"data\\MetroLinkStations_NS.csv\")\n",
    "census_data = data = pd.read_csv(r\"data\\B08119_stl_city.csv\")\n",
    "race_data = pd.read_csv(r\"data\\B08105_stl_city.csv\")\n",
    "stl = nx.read_weighted_edgelist(r\"data\\weighted_dual_list\",delimiter='%',nodetype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82bff8",
   "metadata": {},
   "source": [
    "### Clean the data and set constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452540d",
   "metadata": {},
   "source": [
    "# Population Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f84d8b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() takes from 1 to 2 positional arguments but 3 positional arguments (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m stl\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      9\u001b[0m     stl[edge[\u001b[38;5;241m0\u001b[39m]][edge[\u001b[38;5;241m1\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m total_weight \u001b[38;5;241m-\u001b[39m edge[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m full_data \u001b[38;5;241m=\u001b[39m \u001b[43mclean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcensus_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrace_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m full_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\1410220104.py:20\u001b[0m, in \u001b[0;36mclean\u001b[1;34m(census_data, race_data, pop_centers, centroid_locations, center)\u001b[0m\n\u001b[0;32m     18\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(census_data, not_to_include, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, indicator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m no_totals \u001b[38;5;241m=\u001b[39m merged_df[merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_merge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_only\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_merge\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m---> 20\u001b[0m split_data \u001b[38;5;241m=\u001b[39m \u001b[43mno_totals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m no_totals[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransportation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m split_data\n\u001b[0;32m     22\u001b[0m no_totals\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gdal\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: split() takes from 1 to 2 positional arguments but 3 positional arguments (and 1 keyword-only argument) were given"
     ]
    }
   ],
   "source": [
    "k = 14 #number of clusters/metro stops for all algorithms\n",
    "center = 'POP' # population centers vs geometric centers\n",
    "\n",
    "# adjust edge weights for walking distance (inverse)\n",
    "total_weight = 0\n",
    "for edge in stl.edges(data=True):\n",
    "    total_weight = total_weight + edge[2]['weight'] \n",
    "for edge in stl.edges(data=True):\n",
    "    stl[edge[0]][edge[1]]['weight'] = total_weight - edge[2]['weight']\n",
    "\n",
    "\n",
    "full_data = clean(census_data, race_data, pop_centers, centroid_locations, center)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f241d99",
   "metadata": {},
   "source": [
    "### Original Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d107acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_stops = [[lat, lon] for lat, lon in zip(north_south_locations['LON'],north_south_locations['LAT'])]\n",
    "orig_labels = graph_from_lp(full_data, orig_stops)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],orig_labels)}\n",
    "orig_graph = stl.copy()\n",
    "nx.set_node_attributes(orig_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(orig_graph, \"capstone.gexf\")\n",
    "graph_results_lp(orig_graph, orig_stops, 'Original Plan', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184f5b3",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_weight = 'estimate'\n",
    "k_means_stops, labels = weighted_kmeans(full_data, k, k_means_weight)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],labels)}\n",
    "k_means_graph = stl.copy()\n",
    "nx.set_node_attributes(k_means_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(k_means_graph, \"capstone.gexf\")\n",
    "graph_results_lp(k_means_graph, k_means_stops, 'K-Means', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294e7a3",
   "metadata": {},
   "source": [
    "### Linear Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc889a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_stops = linear_programming(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = graph_from_lp(full_data, lp_stops)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],labels)}\n",
    "lp_graph = stl.copy()\n",
    "nx.set_node_attributes(lp_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(lp_graph, \"capstone.gexf\")\n",
    "graph_results_lp(lp_graph, lp_stops, 'Linear Programming', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da8414",
   "metadata": {},
   "source": [
    "### Modularity Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_max = mod_max_weighted(stl,k)\n",
    "nx.write_gexf(mod_max, \"capstone.gexf\")\n",
    "mm_stops = graph_results(mod_max, 'Modularity Maximization', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f23608",
   "metadata": {},
   "source": [
    "# Evaluating Methods Against One Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_orig_dist = dist_to_nearest_stop_eval(full_data, orig_stops)\n",
    "orig_unweighted_eval = np.mean(total_orig_dist)\n",
    "orig_race_eval = np.dot(full_data['race weight'], total_orig_dist)\n",
    "orig_income_eval = np.dot(full_data['income weight'], total_orig_dist)\n",
    "orig_transit_eval = np.dot(full_data['transit weight'], total_orig_dist)\n",
    "print(f'Original plan unweighted eval: {orig_unweighted_eval}')\n",
    "print(f'Original plan race eval: {orig_race_eval}')\n",
    "print(f'Original plan income eval: {orig_income_eval}')\n",
    "print(f'Original plan transit eval: {orig_transit_eval}\\n')\n",
    "\n",
    "\n",
    "total_lp_dist = dist_to_nearest_stop_eval(full_data, lp_stops)\n",
    "lp_unweighted_eval = np.mean(total_lp_dist)\n",
    "lp_race_eval = np.dot(full_data['race weight'], total_lp_dist)\n",
    "lp_income_eval = np.dot(full_data['income weight'], total_lp_dist)\n",
    "lp_transit_eval = np.dot(full_data['transit weight'], total_lp_dist)\n",
    "print(f'LP unweighted eval: {lp_unweighted_eval}')\n",
    "print(f'LP race eval: {lp_race_eval}')\n",
    "print(f'LP income eval: {lp_income_eval}')\n",
    "print(f'LP transit eval: {lp_transit_eval}\\n')\n",
    "\n",
    "\n",
    "total_km_dist = dist_to_nearest_stop_eval(full_data, k_means_stops)\n",
    "km_unweighted_eval = np.mean(total_km_dist)\n",
    "km_race_eval = np.dot(full_data['race weight'], total_km_dist)\n",
    "km_income_eval = np.dot(full_data['income weight'], total_km_dist)\n",
    "km_transit_eval = np.dot(full_data['transit weight'], total_km_dist)\n",
    "print(f'K-Means unweighted eval: {km_unweighted_eval}')\n",
    "print(f'K-Means race eval: {km_race_eval}')\n",
    "print(f'K-Means income eval: {km_income_eval}')\n",
    "print(f'K-Means transit eval: {km_transit_eval}\\n')\n",
    "\n",
    "total_mm_dist = dist_to_nearest_stop_eval(full_data, mm_stops)\n",
    "mm_unweighted_eval = np.mean(total_mm_dist)\n",
    "mm_race_eval = np.dot(full_data['race weight'], total_mm_dist)\n",
    "mm_income_eval = np.dot(full_data['income weight'], total_mm_dist)\n",
    "mm_transit_eval = np.dot(full_data['transit weight'], total_mm_dist)\n",
    "print(f'Mod Max unweighted eval: {mm_unweighted_eval}')\n",
    "print(f'Mod Max race eval: {mm_race_eval}')\n",
    "print(f'Mod Max income eval: {mm_income_eval}')\n",
    "print(f'Mod Max transit eval: {mm_transit_eval}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr2SHP(np_array, output_shapefile):\n",
    "    df = gpd.GeoDataFrame(geometry=[Point(lonlat) for lonlat in np_array], crs=\"EPSG:4326\")\n",
    "    df.to_file(output_shapefile, driver=\"ESRI Shapefile\")\n",
    "    \n",
    "arr2SHP(orig_stops, \"plans\\OrigStops_p.shp\")\n",
    "arr2SHP(k_means_stops, \"plans\\KMeansStops_p.shp\")\n",
    "arr2SHP(lp_stops, \"plans\\LPStops_p.shp\")\n",
    "arr2SHP(mm_stops, \"plans\\MMStops_p.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2e216",
   "metadata": {},
   "source": [
    "# Geometric Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92986e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = 'GEO' # population centers vs geometric centers\n",
    "full_data = clean(census_data, race_data, pop_centers, centroid_locations, center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f3233",
   "metadata": {},
   "source": [
    "### Original Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_stops = [[lat, lon] for lat, lon in zip(north_south_locations['LON'],north_south_locations['LAT'])]\n",
    "orig_labels = graph_from_lp(full_data, orig_stops)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],orig_labels)}\n",
    "orig_graph = stl.copy()\n",
    "nx.set_node_attributes(orig_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(orig_graph, \"capstone.gexf\")\n",
    "graph_results_lp(orig_graph, orig_stops, 'Original Plan', center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aaf7c3",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a31767",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_weight = 'estimate'\n",
    "k_means_stops, labels = weighted_kmeans(full_data, k, k_means_weight)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],labels)}\n",
    "k_means_graph = stl.copy()\n",
    "nx.set_node_attributes(k_means_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(k_means_graph, \"capstone.gexf\")\n",
    "graph_results_lp(k_means_graph, k_means_stops, 'K-Means', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb82b52",
   "metadata": {},
   "source": [
    "### Linear Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c36f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_stops = linear_programming(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde37ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = graph_from_lp(full_data, lp_stops)\n",
    "cluster_dict = {k:v for k, v in zip(full_data['node id'],labels)}\n",
    "lp_graph = stl.copy()\n",
    "nx.set_node_attributes(lp_graph, cluster_dict, 'cluster')\n",
    "nx.write_gexf(lp_graph, \"capstone.gexf\")\n",
    "graph_results_lp(lp_graph, lp_stops, 'Linear Programming', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34971e7d",
   "metadata": {},
   "source": [
    "### Modularity Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8656c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_max = mod_max_weighted(stl,k)\n",
    "nx.write_gexf(mod_max, \"capstone.gexf\")\n",
    "mm_stops = graph_results(mod_max, 'Modularity Maximization', center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3051100",
   "metadata": {},
   "source": [
    "# Evaluating Methods Against One Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_orig_dist = dist_to_nearest_stop_eval(full_data, orig_stops)\n",
    "orig_unweighted_eval = np.mean(total_orig_dist)\n",
    "orig_race_eval = np.dot(full_data['race weight'], total_orig_dist)\n",
    "orig_income_eval = np.dot(full_data['income weight'], total_orig_dist)\n",
    "orig_transit_eval = np.dot(full_data['transit weight'], total_orig_dist)\n",
    "print(f'Original plan unweighted eval: {orig_unweighted_eval}')\n",
    "print(f'Original plan race eval: {orig_race_eval}')\n",
    "print(f'Original plan income eval: {orig_income_eval}')\n",
    "print(f'Original plan transit eval: {orig_transit_eval}\\n')\n",
    "\n",
    "\n",
    "total_lp_dist = dist_to_nearest_stop_eval(full_data, lp_stops)\n",
    "lp_unweighted_eval = np.mean(total_lp_dist)\n",
    "lp_race_eval = np.dot(full_data['race weight'], total_lp_dist)\n",
    "lp_income_eval = np.dot(full_data['income weight'], total_lp_dist)\n",
    "lp_transit_eval = np.dot(full_data['transit weight'], total_lp_dist)\n",
    "print(f'LP unweighted eval: {lp_unweighted_eval}')\n",
    "print(f'LP race eval: {lp_race_eval}')\n",
    "print(f'LP income eval: {lp_income_eval}')\n",
    "print(f'LP transit eval: {lp_transit_eval}\\n')\n",
    "\n",
    "\n",
    "total_km_dist = dist_to_nearest_stop_eval(full_data, k_means_stops)\n",
    "km_unweighted_eval = np.mean(total_km_dist)\n",
    "km_race_eval = np.dot(full_data['race weight'], total_km_dist)\n",
    "km_income_eval = np.dot(full_data['income weight'], total_km_dist)\n",
    "km_transit_eval = np.dot(full_data['transit weight'], total_km_dist)\n",
    "print(f'K-Means unweighted eval: {km_unweighted_eval}')\n",
    "print(f'K-Means race eval: {km_race_eval}')\n",
    "print(f'K-Means income eval: {km_income_eval}')\n",
    "print(f'K-Means transit eval: {km_transit_eval}\\n')\n",
    "\n",
    "total_mm_dist = dist_to_nearest_stop_eval(full_data, mm_stops)\n",
    "mm_unweighted_eval = np.mean(total_mm_dist)\n",
    "mm_race_eval = np.dot(full_data['race weight'], total_mm_dist)\n",
    "mm_income_eval = np.dot(full_data['income weight'], total_mm_dist)\n",
    "mm_transit_eval = np.dot(full_data['transit weight'], total_mm_dist)\n",
    "print(f'Mod Max unweighted eval: {mm_unweighted_eval}')\n",
    "print(f'Mod Max race eval: {mm_race_eval}')\n",
    "print(f'Mod Max income eval: {mm_income_eval}')\n",
    "print(f'Mod Max transit eval: {mm_transit_eval}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ef02c-0962-44a8-b625-0ff17133e671",
   "metadata": {},
   "source": [
    "## Save plans as point shapefiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d040e10-dede-4fbc-b612-a35b0622f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2SHP(orig_stops, \"plans\\OrigStops.shp\")\n",
    "arr2SHP(k_means_stops, \"plans\\KMeansStops.shp\")\n",
    "arr2SHP(lp_stops, \"plans\\LPStops.shp\")\n",
    "arr2SHP(mm_stops, \"plans\\MMStops.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eef623-0b26-4a96-9073-7da18ded7f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
